{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\") # 为了导入上层目录的d2lzh_tensorflow\n",
    "#import d2lzh_tensorflow2 as d2l\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.1 获取和读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "batch_size = 256\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "train_iter = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "test_iter = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 定义模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "W1 = tf.Variable(tf.random.normal(shape=(num_inputs, num_hiddens),mean=0, stddev=0.01, dtype=tf.float32))\n",
    "b1 = tf.Variable(tf.zeros(num_hiddens, dtype=tf.float32))\n",
    "W2 = tf.Variable(tf.random.normal(shape=(num_hiddens, num_outputs),mean=0, stddev=0.01, dtype=tf.float32))\n",
    "b2 = tf.Variable(tf.random.normal([num_outputs], stddev=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.3 定义激活函数\n",
    "\n",
    "这里我们使用基础的max函数来实现ReLU，而非直接调用relu函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return tf.math.maximum(x,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.4 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = tf.reshape(X, shape=[-1, num_inputs])\n",
    "    h = relu(tf.matmul(X, W1) + b1)\n",
    "    return tf.math.softmax(tf.matmul(h, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.5 定义损失函数\n",
    "为了得到更好的数值稳定性，我们直接使用Tensorflow提供的包括softmax运算和交叉熵损失计算的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y_hat,y_true):\n",
    "    return tf.losses.sparse_categorical_crossentropy(y_true,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.6 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n=0.0,0\n",
    "    for _,(X,y) in enumerate(data_iter):\n",
    "        y=tf.cast(y,dtype=tf.int64)\n",
    "        acc_sum+=np.sum(tf.cast(tf.argmax(net(X),axis=1),dtype=tf.int64)==y)\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1,loss=0.484,train_acc=0.82,test_acc=0.837\n",
      "epoch=2,loss=0.4182,train_acc=0.844,test_acc=0.85\n",
      "epoch=3,loss=0.3859,train_acc=0.857,test_acc=0.857\n",
      "epoch=4,loss=0.364,train_acc=0.866,test_acc=0.862\n",
      "epoch=5,loss=0.3472,train_acc=0.871,test_acc=0.866\n"
     ]
    }
   ],
   "source": [
    "num_epochs,lr=5,0.5\n",
    "params=[W1,b1,W2,b2]\n",
    "def train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,trainer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_sum,train_acc_sum,n=0.0,0.0,0\n",
    "        for X,y in train_iter:\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_hat=net(X)\n",
    "                l=tf.reduce_sum(loss(y_hat,y))\n",
    "            grads=tape.gradient(l,params)\n",
    "            if trainer is None:\n",
    "                #如果没有传入优化器，则使用原来编写的小批量随机梯度下降\n",
    "                for i,param in enumerate(params):\n",
    "                    param.assign_sub(lr*grads[i]/batch_size)\n",
    "            else:\n",
    "                trainer.apply_gradient(zip([grad/batch_size for grad in grads],params))\n",
    "            y=tf.cast(y,dtype=tf.float32)\n",
    "            train_loss_sum+=l.numpy()\n",
    "            train_acc_sum+=tf.reduce_sum(tf.cast(tf.argmax(y_hat,axis=1)==tf.cast(y,dtype=tf.int64),dtype=tf.int64)).numpy()\n",
    "            n+=y.shape[0]\n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('epoch={},loss={:.4},train_acc={:.3},test_acc={:.3}'.format(epoch+1,train_loss_sum/n,train_acc_sum/n,test_acc))\n",
    "train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
